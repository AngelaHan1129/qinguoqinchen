from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import numpy as np
import hashlib
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="ä¾µåœ‹ä¾µåŸ AI Embedding Service (Lite)",
    description="è¼•é‡ç‰ˆæ–‡æœ¬å‘é‡åŒ–æœå‹™",
    version="1.0.0-lite"
)

class EmbeddingRequest(BaseModel):
    text: str
    normalize: bool = True

class EmbeddingResponse(BaseModel):
    embedding: List[float]
    dimension: int
    model: str
    processing_time: float
    text_length: int

class MockEmbeddingModel:
    def __init__(self):
        self.model_name = "mock-e5-large-v2"
        self.dimension = 1024
        logger.info("âœ… æ¨¡æ“¬åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def encode(self, text: str, normalize_embeddings: bool = True) -> np.ndarray:
        # ä½¿ç”¨æ–‡æœ¬å“ˆå¸Œç”Ÿæˆå›ºå®šä½†å”¯ä¸€çš„å‘é‡
        hash_obj = hashlib.md5(text.encode('utf-8'))
        hash_bytes = hash_obj.digest()
        
        # æ“´å±•åˆ° 1024 ç¶­
        vector = []
        for i in range(self.dimension):
            byte_idx = i % len(hash_bytes)
            vector.append((hash_bytes[byte_idx] / 255.0) - 0.5)  # æ­¸ä¸€åŒ–åˆ° [-0.5, 0.5]
        
        vector = np.array(vector, dtype=np.float32)
        
        if normalize_embeddings:
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = vector / norm
                
        return vector

# å…¨åŸŸæ¨¡å‹å¯¦ä¾‹
model = MockEmbeddingModel()

@app.get("/")
async def root():
    return {
        "service": "ä¾µåœ‹ä¾µåŸ AI Embedding Service (Liteç‰ˆæœ¬)",
        "version": "1.0.0-lite",
        "description": "è¼•é‡ç‰ˆå‘é‡åŒ–æœå‹™ï¼Œç”¨æ–¼é–‹ç™¼æ¸¬è©¦",
        "model": {
            "name": "mock-e5-large-v2",
            "dimension": 1024,
            "status": "loaded",
            "type": "simulation"
        },
        "note": "é€™æ˜¯æ¨¡æ“¬ç‰ˆæœ¬ï¼Œç”Ÿç”¢ç’°å¢ƒè«‹ä½¿ç”¨å®Œæ•´ç‰ˆ",
        "endpoints": {
            "embed": "POST /embed - æ–‡æœ¬å‘é‡åŒ–",
            "health": "GET /health - å¥åº·æª¢æŸ¥"
        }
    }

@app.post("/embed", response_model=EmbeddingResponse)
async def create_embedding(request: EmbeddingRequest):
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬å…§å®¹ä¸èƒ½ç‚ºç©º")
    
    try:
        start_time = time.time()
        
        embedding = model.encode(request.text, request.normalize)
        processing_time = time.time() - start_time
        
        logger.info(f"ğŸ“ è™•ç†æ–‡æœ¬: {request.text[:50]}...")
        
        return EmbeddingResponse(
            embedding=embedding.tolist(),
            dimension=len(embedding),
            model="mock-e5-large-v2",
            processing_time=processing_time,
            text_length=len(request.text)
        )
        
    except Exception as e:
        logger.error(f"âŒ å‘é‡ç”Ÿæˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å‘é‡ç”Ÿæˆå¤±æ•—: {str(e)}")

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "ä¾µåœ‹ä¾µåŸ AI Embedding Service (Lite)",
        "version": "1.0.0-lite",
        "model": {
            "name": "mock-e5-large-v2",
            "status": "loaded",
            "dimension": 1024,
            "type": "simulation"
        },
        "system": {
            "ready": True,
            "note": "è¼•é‡ç‰ˆæœå‹™ï¼Œé©ç”¨æ–¼é–‹ç™¼æ¸¬è©¦"
        },
        "timestamp": time.time()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
