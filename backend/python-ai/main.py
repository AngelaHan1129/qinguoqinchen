# python-ai/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Optional
import logging
import time

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="ä¾µåœ‹ä¾µåŸ AI Embedding Service",
    description="æ–‡æœ¬å‘é‡åŒ–æœå‹™ï¼Œå°ˆç‚º RAG ç³»çµ±è¨­è¨ˆ",
    version="1.0.0"
)

# å…¨åŸŸè®Šæ•¸å­˜å„²æ¨¡å‹
model = None

class EmbeddingRequest(BaseModel):
    text: str
    normalize: bool = True

class EmbeddingResponse(BaseModel):
    embedding: List[float]
    dimension: int
    model: str
    processing_time: float

class BatchEmbeddingRequest(BaseModel):
    texts: List[str]
    normalize: bool = True

class BatchEmbeddingResponse(BaseModel):
    embeddings: List[List[float]]
    dimension: int
    model: str
    count: int
    processing_time: float

@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡å‹"""
    global model
    try:
        logger.info("ğŸš€ è¼‰å…¥ E5-Large-V2 åµŒå…¥æ¨¡å‹...")
        model = SentenceTransformer('intfloat/e5-large-v2')
        logger.info("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        raise

@app.get("/")
async def root():
    return {
        "service": "ä¾µåœ‹ä¾µåŸ AI Embedding Service",
        "version": "1.0.0",
        "model": "intfloat/e5-large-v2",
        "endpoints": {
            "embed": "POST /embed - å–®ä¸€æ–‡æœ¬å‘é‡åŒ–",
            "embed/batch": "POST /embed/batch - æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–",
            "health": "GET /health - å¥åº·æª¢æŸ¥"
        }
    }

@app.post("/embed", response_model=EmbeddingResponse)
async def create_embedding(request: EmbeddingRequest):
    """ç”Ÿæˆå–®ä¸€æ–‡æœ¬å‘é‡"""
    if not model:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªè¼‰å…¥")
    
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="æ–‡æœ¬å…§å®¹ä¸èƒ½ç‚ºç©º")
    
    try:
        start_time = time.time()
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        embedding = model.encode(
            request.text, 
            normalize_embeddings=request.normalize
        )
        
        processing_time = time.time() - start_time
        
        return EmbeddingResponse(
            embedding=embedding.tolist(),
            dimension=len(embedding),
            model="intfloat/e5-large-v2",
            processing_time=processing_time
        )
    except Exception as e:
        logger.error(f"âŒ å‘é‡ç”Ÿæˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"å‘é‡ç”Ÿæˆå¤±æ•—: {str(e)}")

@app.post("/embed/batch", response_model=BatchEmbeddingResponse)
async def create_batch_embeddings(request: BatchEmbeddingRequest):
    """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡"""
    if not model:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªè¼‰å…¥")
    
    if not request.texts or len(request.texts) == 0:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬åˆ—è¡¨ä¸èƒ½ç‚ºç©º")
    
    # é™åˆ¶æ‰¹é‡å¤§å°
    if len(request.texts) > 100:
        raise HTTPException(status_code=400, detail="æ‰¹é‡å¤§å°ä¸èƒ½è¶…é 100")
    
    try:
        start_time = time.time()
        
        # æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
        embeddings = model.encode(
            request.texts, 
            normalize_embeddings=request.normalize,
            batch_size=32
        )
        
        processing_time = time.time() - start_time
        
        return BatchEmbeddingResponse(
            embeddings=[emb.tolist() for emb in embeddings],
            dimension=len(embeddings[0]) if len(embeddings) > 0 else 0,
            model="intfloat/e5-large-v2",
            count=len(embeddings),
            processing_time=processing_time
        )
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡å‘é‡ç”Ÿæˆå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡å‘é‡ç”Ÿæˆå¤±æ•—: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    model_status = "loaded" if model is not None else "not_loaded"
    
    return {
        "status": "healthy" if model is not None else "unhealthy",
        "service": "ä¾µåœ‹ä¾µåŸ Embedding Service",
        "model": {
            "name": "intfloat/e5-large-v2",
            "status": model_status,
            "dimension": 1024
        },
        "system": {
            "cpu_count": "available",
            "memory": "sufficient"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
